from flask import Flask, render_template, request, jsonify
from transformers import AutoTokenizer, LEDForConditionalGeneration
import torch

app = Flask(__name__)

model_name = "ruchita1010/LED_billsum_model"
tokenizer = AutoTokenizer.from_pretrained("ruchita1010/LED_billsum_model")

device = "cuda" if torch.cuda.is_available() else "cpu"
model = LEDForConditionalGeneration.from_pretrained("ruchita1010/LED_billsum_model")


@app.route('/', methods=['GET'])
def home():
    return render_template('index.html')


@app.route('/text-summarization', methods=["POST"])
def summarize():
    if request.method == "POST":
        inputtext = request.form["inputtext_"]

        input_text = "summarize: " + inputtext

        tokenized_text = tokenizer.encode(input_text, return_tensors='pt', max_length=512).to(device)
        summary_ = model.generate(tokenized_text, min_length=30, max_length=300)
        summary = tokenizer.decode(summary_[0], skip_special_tokens=True)

        return jsonify({"summary": summary})


if __name__ == '__main__':  # It Allows You to Execute Code When the File Runs as a Script
    app.run(host="0.0.0.0",port=5000,debug=True)
